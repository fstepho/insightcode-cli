# InsightCode Benchmarks Documentation

This directory contains benchmark results and analysis of popular open-source projects.

## ðŸŽ¯ Purpose

- Validate InsightCode's scoring algorithm
- Demonstrate real-world performance
- Provide reference scores for comparison
- Build credibility through transparent analysis

## ðŸ“Š Latest Results

The most recent benchmark results are generated by running:
```bash
npm run benchmark
```

Results are saved to `benchmark-results/BENCHMARKS.md` (git-ignored).
Significant results are archived in this directory.

## ðŸ“ Methodology

### Measurement Accuracy
Based on our validation tests (**100% accuracy** on known complexity values):

#### Complexity Calculation
- **Method**: Cyclomatic Complexity (McCabe, 1976)
- **Accuracy**: 100% validated with comprehensive test suite
- **Base**: Every file starts at complexity 1
- **+1 for each**:
  - `if`, `else if` (but NOT `else` alone)
  - `for`, `while`, `do-while`, `for-in`, `for-of`
  - `case` in switch (but NOT `default`)
  - `catch` in try-catch
  - `&&`, `||`, `??` (everywhere, including return statements)
  - `? :` (ternary operator)
- **Calculation**: Sum of all decision points in the entire file

#### Duplication Detection
- **Method**: 5-line sliding window with MD5 hashing
- **Conservative**: May underreport actual duplication (~85% accuracy in tests)
- **Includes**: Test files and examples in the analysis
- **Threshold**: Blocks appearing 2+ times are counted as duplicated

#### Important Considerations
1. **Test Files Included**: Scores include test files which often have high duplication
2. **File-level Analysis**: Complexity is calculated for the entire file, not per function
3. **Large Projects**: May fail with ENOBUFS (TypeScript, Webpack exceeded buffer limits)

## ðŸ“ˆ Historical Benchmarks

When we have significant results worth preserving:
1. Copy `benchmark-results/BENCHMARKS.md` to this directory
2. Rename with date: `benchmark-2025-06-26.md`
3. Update key findings in this README

## ðŸ” Key Findings (v0.1.0 - June 26, 2025)

### Score Distribution (Reality Check!)
Based on analysis of 19 popular projects:
- **0 projects** got an A grade
- **2 projects** got a B grade (11%)
- **9 projects** got a C grade (47%)
- **2 projects** got a D grade (11%)
- **4 projects** got an F grade (21%)

**Insight**: Even the most popular projects have technical debt!

### Performance
- Average analysis speed: **35,792 lines/second**
- Largest successful: ESLint (463,573 lines) in 3.6 seconds
- Failed: TypeScript, Webpack (too large - ENOBUFS)

### Surprising Results
1. **ms** (4.8k â­): Expected A, got **D** - complexity 55 in index.ts!
2. **ESLint** (25k â­): Got **F** - the irony of a linter with bad code
3. **Prettier** (49k â­): Best score with **B** (89/100)

## ðŸ† Notable Scores

| Project | Stars | Grade | Reality |
|---------|-------|-------|---------|
| prettier | 49k | B (89) | Only formatter that formats its own code well |
| commander | 26k | C (80) | Best C score - but command.js has complexity 341! |
| ms | 4.8k | D (64) | Popular â‰  Simple - index.ts complexity 55 |
| joi | 21k | F (27) | Worst score - base.js complexity 150 |
| eslint | 25k | F (34) | The linter that needs linting |

## ðŸ“ Using Benchmarks

### For Marketing (Honest Version)
- "Even axios (104k â­) scores C - your C is respectable!"
- "Successfully analyzed ESLint - 463k lines in 3.6 seconds"
- "No sugar-coating - real scores from real projects"

### For Validation
- âœ… Strict scoring - no grade inflation
- âœ… Performance proven - 35k+ lines/second
- âœ… Finds real issues - command.js with 341 complexity

### For Setting Expectations
- **A grade**: Rare, exceptional code
- **B grade**: Excellent, hard to achieve (11% of projects)
- **C grade**: Good, industry standard (47% of projects)
- **D grade**: Needs work
- **F grade**: Major refactoring needed

## ðŸ”„ Update Schedule

- Run benchmarks before each release
- Document significant changes
- Keep findings honest and transparent

## ðŸ’¡ Lessons Learned

1. **InsightCode is strict** - No project got above B
2. **That's a feature** - Honest feedback > feel-good scores
3. **C is the new A** - If axios has C, so can you
4. **Popular â‰  Quality** - Stars don't guarantee clean code

---

*Last benchmark: June 26, 2025 - 17/19 projects analyzed successfully*
*Validation accuracy: 100% for complexity, ~85% for duplication*